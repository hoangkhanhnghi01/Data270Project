# -*- coding: utf-8 -*-
"""SWE NULL cleanup.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Zf9nyW5jcEegV98wy32jQmBvuvmb2ND4
"""

from google.colab import drive
import sqlite3
import os
import pandas as pd
import numpy as np
from scipy import stats
import matplotlib.pyplot as plt

drive.mount('/content/drive')

!ls "/content/drive/MyDrive/Data 270 project/Data"

def create_df(table_name, column_names, col_names_str = "*", condition = ""):
    cur.execute(f'SELECT {col_names_str} FROM {table_name} {condition}')
    data = cur.fetchall()
    df = pd.DataFrame(np.array(data), columns = column_names)
    return df


def checkdb(db):
    if os.path.exists(db)==True:
        conn=sqlite3.connect(db)
        con=conn.cursor()
        return con
    else:
        print(".Db does not exist")

directory = "/content/drive/MyDrive/Data 270 project/Data"
db = r'/270Database.db'

# check if the db still in the directory folder.
checkdb(directory + db)

con = sqlite3.connect(directory + db)
cur = con.cursor()

#snow_table_name = "snow_data_project"
#snow_col_names = ["Date", "Station_Name", "Station_id", "Snow_Water_Equivalent_(in)_Start_of_Day_Values", 
                 # "Change_In_Snow_Water_Equivalent_(in)", "Snow_Depth_(in)_Start_of_Day_Values", "Change_In_Snow_Depth_(in)"]

## Histogram
snow_table_name = "snow_data"
snow_col_names = ["Date", "Station_Name", "Station_id", "Snow_Water_Equivalent_(in)_Start_of_Day_Values", 
                  "Change_In_Snow_Water_Equivalent_(in)", "Snow_Depth_(in)_Start_of_Day_Values", "Change_In_Snow_Depth_(in)"]

# create df
snow_df = create_df(table_name=snow_table_name, column_names=snow_col_names,condition="ORDER BY Station_Name" )
snow_df_raw=create_df(table_name="snow_data", column_names=snow_col_names,condition="ORDER BY Station_Name")

snow_df_raw

#Normalize Dates
snow_date = snow_df["Date"].tolist()
for i in range(len(snow_date)):
    date_str = snow_date[i].split("/")
    if len(date_str) == 3 :
        if len(date_str[0]) == 1:
            date_str[0] = "0" + date_str[0]
        if len(date_str[1]) == 1:
            date_str[1] = "0" + date_str[1]
        snow_date[i] = date_str[2] + "-" + date_str[0] + "-" + date_str[1] 
snow_df["Date"] = snow_date

#sort by station then dates

s_df = snow_df.sort_values(by=['Station_Name','Date'])[snow_df["Date"] >= "2014-01-01"].reset_index(drop = True)
s_df = s_df.sort_values(by=['Station_Name','Date'])[s_df["Date"] <= "2022-03-31"].reset_index(drop = True)

#s_df.groupby('Station_Name').size()
plt.figure(figsize=(36,8.5))
plt.xticks(rotation='vertical')
plt.hist(s_df['Station_Name'],84,edgecolor="black")


plt.show()

#check for amount null values in Snow_Water_Equivalent_(in)_Start_of_Day_Values

s_df[s_df["Snow_Water_Equivalent_(in)_Start_of_Day_Values"]=='']

#insert 0 into data sets as entire month is 0 inches

for index, row in s_df[s_df["Snow_Water_Equivalent_(in)_Start_of_Day_Values"]==''].iterrows():
  s_df.iloc[index,3]=0

s_df.to_csv(r'/content/drive/MyDrive/Data 270 project/Data/snow_data.csv')

"""Separate Work"""

s_df['Snow_Water_Equivalent_(in)_Start_of_Day_Values']=pd.to_numeric(s_df['Snow_Water_Equivalent_(in)_Start_of_Day_Values'])
s_df['Change_In_Snow_Water_Equivalent_(in)']=pd.to_numeric(s_df['Change_In_Snow_Water_Equivalent_(in)'])
s_df['Snow_Depth_(in)_Start_of_Day_Values']=pd.to_numeric(s_df['Snow_Depth_(in)_Start_of_Day_Values'])
s_df['Change_In_Snow_Depth_(in)']=pd.to_numeric(s_df['Change_In_Snow_Depth_(in)'])

#Outliers 

station_list=s_df['Station_Name'].unique() #Unique station name 

#identify outliers
for station in station_list:
  new_df= s_df[s_df['Station_Name']==station]
  plt.scatter(['Change_In_Snow_Water_Equivalent_(in)'])
  plt.show()

s_df['Change_In_Snow_Water_Equivalent_(in)'].describe()

s_df.describe()

