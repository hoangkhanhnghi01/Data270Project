# -*- coding: utf-8 -*-
"""Copy of modeling_with swe.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YTNPsa4cpsCE6o20lqYx2SmRUM_V0k0C
"""

from google.colab import drive

# import sqlite3

import os

# import math
# import geopy.distance
from scipy.stats import reciprocal, uniform

import pandas as pd
import numpy as np

import matplotlib.pyplot as plt
import seaborn as sns

from functools import reduce

from sklearn.model_selection import train_test_split
from sklearn.svm import SVR
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import RandomizedSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_absolute_percentage_error
from sklearn.metrics import mean_absolute_error
from xgboost import XGBRegressor

drive.mount('/content/drive')
directory = "/content/drive/MyDrive/SJSU/aaa DATA 270/Data 270 project/Data"
!ls "/content/drive/MyDrive/SJSU/aaa DATA 270/Data 270 project/Data"

directory = "/content/drive/MyDrive/SJSU/aaa DATA 270/Data 270 project/Data"

"""# Time Series with SVM adding SUM_SWE (snow equivalent water)"""

swe_df = pd.read_csv(directory + '/COMBINED_TABLE.csv', 
                     usecols = ['DATE',  'SUM_SWE', 'storage'], 
                     parse_dates = ["DATE"], 
                     index_col = "DATE")
swe_df.iloc[:32, :]

date = swe_df.groupby(pd.Grouper(freq='M')).mean().index.tolist()

### storage transform ###
# monthly avg storage
storage_month_avg = swe_df.groupby(pd.Grouper(freq='M')).mean()['storage'].tolist()

# traget value = storage of the end of each month.
storage_end_of_month = swe_df.groupby([swe_df.index.year, swe_df.index.month]).tail(1)['storage'].tolist()

# weekly avg storage
weekly_avg = swe_df.rolling(7).mean()['storage']


### swe transform ###
# monthly sum swe
swe_month_sum = swe_df.groupby(pd.Grouper(freq='M')).sum()['SUM_SWE'].tolist()

# weekly sum swe
swe_weekly_sum = swe_df.rolling(7).sum()['SUM_SWE']

# storage data rolling forward 30 days sum
storage_forward_one_month = swe_df.rolling(30).sum()['storage']/30
storage_forward_one_month = storage_forward_one_month.groupby([storage_forward_one_month.index.year, storage_forward_one_month.index.month]).tail(1)

storage_forward_one_month

swe_df.groupby(pd.Grouper(freq='M')).mean()['storage']

# credit new df for SVR
swe_svr_df = pd.DataFrame(np.array([date, swe_month_sum, storage_month_avg, storage_forward_one_month.tolist()]).transpose(), 
                          columns = ['date', 'monthly_sum_swe', 'storage_monthly_avg', "avg_storage_level_next_30_days"])
swe_svr_df = swe_svr_df.set_index("date")

# add weekly avg storage to swe_svr_df
swe_svr_df = swe_svr_df.merge(weekly_avg, left_index = True, right_index = True)
swe_svr_df_col_names = swe_svr_df.columns.tolist()
swe_svr_df_col_names[-1] = "week_avg_storage_level"
swe_svr_df.columns = swe_svr_df_col_names
swe_svr_df.insert(1, 'week_avg_storage_level', swe_svr_df.pop('week_avg_storage_level'))

# # add weekly sum swe to swe_svr_df
swe_svr_df = swe_svr_df.merge(swe_weekly_sum, left_index = True, right_index = True)
swe_svr_df_col_names = swe_svr_df.columns.tolist()
swe_svr_df_col_names[-1] = "week_sum_swe"
swe_svr_df.columns = swe_svr_df_col_names
swe_svr_df.insert(0, 'week_sum_swe', swe_svr_df.pop('week_sum_swe'))
swe_svr_df = swe_svr_df.reset_index()
swe_svr_df_col_names = swe_svr_df.columns.tolist()
swe_svr_df_col_names[0] = "date"
swe_svr_df.columns = swe_svr_df_col_names

# add target value
# swe_svr_df = swe_svr_df.merge(storage_forward_one_month, left_index = True, right_index = True)
# swe_svr_df_col_names = swe_svr_df.columns.tolist()
# swe_svr_df_col_names[-1] = "storage_forward_one_month"
# swe_svr_df.columns = swe_svr_df_col_names
# swe_svr_df.insert(1, 'storage_forward_one_month', swe_svr_df.pop('storage_forward_one_month'))
# swe_svr_df = swe_svr_df.reset_index()
# swe_svr_df_col_names = swe_svr_df.columns.tolist()
# swe_svr_df_col_names[0] = "date"
# swe_svr_df.columns = swe_svr_df_col_names

swe_svr_df

swe_svr_df.iloc[-10:, :]

"""## Scaling Values"""

scale = StandardScaler()
scale_swe_svr_df = scale.fit_transform(swe_svr_df.iloc[:, 1:])
scale_swe_svr_df = pd.DataFrame(scale_swe_svr_df, columns = swe_svr_df.columns[1:])
scale_swe_svr_df.insert(0, "date", swe_svr_df['date'])

scale_swe_svr_df

"""## SVR - predicting the last 16 months"""

features = scale_swe_svr_df.columns.tolist()[1:-1]
label = scale_swe_svr_df.columns.tolist()[-1]
splitting_date = '2020-12-31'
test_df = scale_swe_svr_df[scale_swe_svr_df['date'] >= splitting_date]
train_df = scale_swe_svr_df[scale_swe_svr_df['date'] < splitting_date]
X_train, y_train = train_df[features], train_df[label]
X_test, y_test = test_df[features], test_df[label]

"""### RBF vs. Linear vs. Poly"""

features

rbf_svr = SVR(kernel = 'rbf')
rbf_svr.fit(X_train, y_train)
rbf_y_hat = rbf_svr.predict(X_test)

ts_predictions = pd.DataFrame({'date': scale_swe_svr_df[scale_swe_svr_df['date']>= splitting_date]['date'], 
                               'monthly_sum_swe': scale_swe_svr_df[scale_swe_svr_df['date']>= splitting_date]['monthly_sum_swe'],
                               'week_sum_swe': scale_swe_svr_df[scale_swe_svr_df['date']>= splitting_date]['week_sum_swe'],
                               'storage_monthly_avg': scale_swe_svr_df[scale_swe_svr_df['date']>= splitting_date]['storage_monthly_avg'],
                               'week_avg_storage_level': scale_swe_svr_df[scale_swe_svr_df['date']>= splitting_date]['week_avg_storage_level'], 
                               "y_test": y_test, "y_hat_rbf": rbf_y_hat})

linear_svr = SVR(kernel = 'linear', gamma = "auto")
linear_svr.fit(X_train, y_train)
linear_y_hat = linear_svr.predict(X_test)

ts_predictions['y_hat_linear'] = linear_y_hat

poly_svr = SVR(kernel = 'poly')
poly_svr.fit(X_train, y_train)
poly_y_hat = poly_svr.predict(X_test)

ts_predictions['y_hat_poly'] = poly_y_hat

plt.rcParams.update({'figure.figsize': (25, 10), 'figure.dpi':300})
fig, ax = plt.subplots()
sns.lineplot(data = scale_swe_svr_df, x='date', y=features[-1])
sns.lineplot(data = ts_predictions, x='date', y='y_hat_rbf', color = "orange", label = "rbf")
sns.lineplot(data = ts_predictions, x='date', y='y_hat_linear', color = "red", label = 'linear')
sns.lineplot(data = ts_predictions, x='date', y='y_hat_poly', color = "green", label = 'poly')
plt.grid(linestyle='-', linewidth=0.3)
plt.ylabel('avg_storage_level_next_30_days (target)')
plt.xlabel('year')

# ax.tick_params(axis='x', rotation=90)

"""Graph Linear Only"""

plt.rcParams.update({'figure.figsize': (25, 10), 'figure.dpi':300})
fig, ax = plt.subplots()
sns.lineplot(data = scale_swe_svr_df, x='date', y=features[-1])
sns.lineplot(data = ts_predictions, x='date', y='y_hat_linear', color = "red", label = 'linear', 
             linewidth = 4)
sns.lineplot(data = ts_predictions, x='date', y='y_hat_rbf', color = "orange", label = "rbf")
sns.lineplot(data = ts_predictions, x='date', y='y_hat_poly', color = "green", label = 'poly')
plt.grid(linestyle='-', linewidth=0.3)
# ax.tick_params(axis='x', rotation=90)

plt.rcParams.update({'figure.figsize': (5, 5), 'figure.dpi':300})
sns.scatterplot(x = y_test, y = linear_y_hat)
sns.lineplot(y_test, y_test)
plt.xlabel("Actual Storage Value")
plt.ylabel("Predicted Storage Value")
plt.title("Actual vs Predicted (linear kernel)")
plt.show()

"""Compare the R score of Linear and RBF"""

print("SWE_SVR_DF:")
print()

print("Linear: r sqaured", linear_svr.score(X_test, y_test))
print("Linear: r", np.corrcoef(y_test, linear_y_hat)[0, 1])
linear_MSE_test = round(np.mean(np.square(y_test - linear_y_hat)), 5)
linear_RMSE_test = round(np.sqrt(linear_MSE_test), 5)
print("Linear: MAPE", mean_absolute_percentage_error(y_test, linear_y_hat))
print("Linear: MAE", mean_absolute_error(y_test, linear_y_hat))
print("Linear: RMSE", linear_RMSE_test)
print("-----------------------------")
print("RBF: r sqaured", rbf_svr.score(X_test, y_test))
print("RBF: r", np.corrcoef(y_test, rbf_y_hat)[0, 1])
rbf_MSE_test = round(np.mean(np.square(y_test - rbf_y_hat)), 5)
rbf_RMSE_test = round(np.sqrt(rbf_MSE_test), 5)
print("RBF: RMSE", rbf_RMSE_test)
print("RBF: MAPE", mean_absolute_percentage_error(y_test, rbf_y_hat))
print("RBF: MAE", mean_absolute_error(y_test, rbf_y_hat))
print("-----------------------------")
print(f"{'Linear' if linear_svr.score(X_test, y_test) > rbf_svr.score(X_test, y_test) else False} outperform {'RBF' if linear_svr.score(X_test, y_test) > rbf_svr.score(X_test, y_test) else 'RBF'}!")



"""### gridsearch on Linear"""

# When training an SVM with the Radial Basis Function (RBF) kernel, 
# two parameters must be considered: C and gamma. 
# The parameter C, common to all SVM kernels, 
# trades off misclassification of training examples against simplicity of the decision surface. 
# A low C makes the decision surface smooth, 
# while a high C aims at classifying all training examples correctly. 
# gamma defines how much influence a single training example has. 
# The larger gamma is, the closer other examples must be to be affected.
ts_param_grid = {'kernel': ['linear'], "C": [10, 100, 1000], "gamma": [0.001, 0.0001], "epsilon": [0.001, 0.0001]}
ts_grid = GridSearchCV(estimator = SVR(), param_grid = ts_param_grid, refit = True, verbose = 3, cv = 10)
print(ts_grid)
ts_grid.fit(X_train, y_train)
best_est = ts_grid.best_params_
print(ts_grid.best_params_)
print(ts_grid.best_score_)

# param_distributions = {"gamma": reciprocal(0.001, 0.1), "C": uniform(1, 100)}
# rnd_search_cv = RandomizedSearchCV(SVR(), param_distributions, n_iter=10, verbose=2, cv=10, random_state = 42)
# rnd_search_cv.fit(X_train, y_train)

best_est

"""### Cross Validation with the best parameters"""

### for randomized search ###
ts_mae = cross_val_score(SVR(C = best_est["C"], gamma = best_est["gamma"], epsilon = best_est["epsilon"]),
                       X = X_train, y = y_train, scoring = "neg_mean_absolute_error")
ts_rmse = cross_val_score(SVR(C = best_est["C"], gamma = best_est["gamma"], epsilon = best_est["epsilon"]),
                       X = X_train, y = y_train, scoring = "neg_root_mean_squared_error")
ts_r2 = cross_val_score(SVR(C = best_est["C"], gamma = best_est["gamma"], epsilon = best_est["epsilon"]),
                       X = X_train, y = y_train, scoring = "r2")
print("mae:", round(np.mean(ts_mae)*-1, 5))
print("rmse:", round(np.mean(ts_rmse)*-1, 5))
print("r2:", round(np.mean(ts_r2), 5))

"""### Prediction Results"""

# reverse scaling setup
reverse_scaler = StandardScaler().fit(np.array(swe_svr_df.iloc[:, -1]).reshape(-1, 1))

# reverse scaling
reversed_predicted_values = reverse_scaler.inverse_transform(linear_y_hat.reshape(-1, 1)).reshape(16,).tolist()
reversed_y_test = reverse_scaler.inverse_transform(np.array(y_test).reshape(-1, 1)).reshape(16,).tolist()

# calculating error
difference = np.subtract(np.array(reversed_y_test), np.array(reversed_predicted_values).tolist())
difference_percentage = [i/j *100 for i, j in zip(difference, reversed_y_test)]



# create df for prediction result
prediction_table = pd.DataFrame(np.array([ts_predictions['date'].tolist(), reversed_y_test, 
                       reversed_predicted_values, 
                      difference, 
                       difference_percentage]).transpose(), 
             columns = ['date', 'y', 'y_hat', 'error', 'error in %'])

prediction_table

np.mean(prediction_table.iloc[:, -1])

plt.rcParams.update({'figure.figsize': (25, 10), 'figure.dpi':300})
fig, ax = plt.subplots()
sns.lineplot(data = swe_svr_df, x= label)
sns.lineplot(data = prediction_table, x='date', y='y_hat', color = "red", label = 'prediction', 
             linewidth = 4)
# sns.lineplot(data = ts_predictions, x='week', y='y_hat_rbf', color = "orange", label = "rbf")
# sns.lineplot(data = ts_predictions, x='week', y='y_hat_poly', color = "green", label = 'poly')
plt.grid(linestyle='-', linewidth=0.3)
plt.xlabel("Year")
plt.ylabel("Storage Level")



"""## Different Testing and Training ratio Comparisons


"""

features = scale_swe_svr_df.columns.tolist()[1:-1]
label = scale_swe_svr_df.columns.tolist()[-1]

year = ['2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021']
month = ['06', '12']

date_ls = []
r2_score_ls = []
RMSE_ls = []

y_hat_date_ls = []

for y in year:
    for m in month:
        # determine splitting date
        if m == '06':
            splitting_date = y + "-" + m + "-30"
        else: 
            splitting_date = y + "-" + m + "-31"
        date_ls.append(splitting_date)
        
        # splitting data
        test_df = scale_swe_svr_df[scale_swe_svr_df['date'] >= splitting_date]
        train_df = scale_swe_svr_df[scale_swe_svr_df['date'] < splitting_date]
        X_train, y_train = train_df[features], train_df[label]
        X_test, y_test = test_df[features], test_df[label]

        # fit model
        linear_svr = SVR(kernel = 'linear')
        linear_svr.fit(X_train, y_train)
        linear_y_hat = linear_svr.predict(X_test)

        dates = scale_swe_svr_df[scale_swe_svr_df['date']>= splitting_date]['date']

        # appending result
        r2_score_ls.append(linear_svr.score(X_test, y_test))
        linear_MSE_test = round(np.mean(np.square(y_test - linear_y_hat)), 5)
        RMSE_ls.append(round(np.sqrt(linear_MSE_test), 5))

        y_hat_date_ls.append((dates, linear_y_hat))

prediction_results_df = pd.DataFrame(np.array([date_ls, r2_score_ls, RMSE_ls]).transpose(), columns = ['train_test_splitting_by', 'r2_score', 'RMSE'])

prediction_results_df['r2_score'] = pd.to_numeric(prediction_results_df['r2_score'])
prediction_results_df['RMSE'] = pd.to_numeric(prediction_results_df['RMSE'])

fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(10,4))
sns.lineplot( x=np.linspace(1, 8.5, 16), y=prediction_results_df['r2_score'], color = "blue", label = 'R2 Score', ax = ax[0])
ax[0].set_xlabel("year")
ax[0].set_ylabel("R2 Score")
ax[0].set_title("R2 Score Trend")
sns.lineplot( x=np.linspace(1, 8.5, 16), y=prediction_results_df['RMSE'], color = "orange", label = 'RMSE', ax = ax[1])
ax[1].set_xlabel("year")
ax[1].set_ylabel("RMSE")
ax[1].set_title("RMSE Trend")

y_hat_date_ls.reverse()

y_hat_date_ls

plt.figure(figsize = (30, 30))
for i in range(16):
    index = 16
    # fig, ax = plt.subplots(nrows=3, ncols=4, figsize=(12, 6))
    ax = plt.subplot(6, 3, i+1)
    sns.lineplot(data = scale_swe_svr_df, x = 'date', y = label, ax = ax)
    sns.lineplot(x = y_hat_date_ls[i][0], y = y_hat_date_ls[i][1], ax = ax)
    ax.set_xlabel("year")
    ax.set_ylabel("storage")

predictions = reg.predict(X_test)

predictions

xg_svm_predictions_df = pd.DataFrame(
    {'date': scale_swe_svr_df[scale_swe_svr_df['date']>= splitting_date]['date'], 
     "y_test": y_test, "y_hat_svm_linear": linear_y_hat, "y_hat_xgboost": predictions}
     )

xg_svm_predictions_df

plt.rcParams.update({'figure.figsize': (25, 10), 'figure.dpi':300})
fig, ax = plt.subplots()
sns.lineplot(data = scale_swe_svr_df, x='date', y='next_month_avg_storage (target)')
sns.lineplot(data = xg_svm_predictions_df, x='date', y='y_hat_svm_linear', color = "red", label = 'svm')
sns.lineplot(data = xg_svm_predictions_df, x='date', y='y_hat_xgboost', color = "orange", label = "xgboost")
plt.grid(linestyle='-', linewidth=0.3)
# ax.tick_params(axis='x', rotation=90)

# reverse scaling setup
reverse_scaler = StandardScaler().fit(np.array(swe_svr_df.iloc[:, -1]).reshape(-1, 1))

# svm_reverse scaling
svm_reversed_predicted_values = reverse_scaler.inverse_transform(linear_y_hat.reshape(-1, 1)).reshape(16,).tolist()
svm_reversed_y_test = reverse_scaler.inverse_transform(np.array(y_test).reshape(-1, 1)).reshape(16,).tolist()

# svm_calculating error
svm_difference = np.subtract(np.array(svm_reversed_y_test), np.array(svm_reversed_predicted_values).tolist())
svm_difference_percentage = [i/j *100 for i, j in zip(svm_difference, svm_reversed_y_test)]

# xgb_reverse scaling
xgb_reversed_predicted_values = reverse_scaler.inverse_transform(predictions.reshape(-1, 1)).reshape(16,).tolist()
xgb_reversed_y_test = reverse_scaler.inverse_transform(np.array(y_test).reshape(-1, 1)).reshape(16,).tolist()

# xgb_calculating error
xgb_difference = np.subtract(np.array(xgb_reversed_y_test), np.array(xgb_reversed_predicted_values).tolist())
xgb_difference_percentage = [i/j *100 for i, j in zip(xgb_difference, xgb_reversed_y_test)]

# create df for prediction result
prediction_table = pd.DataFrame(np.array([ts_predictions['date'].tolist(), 
                                          reversed_y_test, 
                                          svm_reversed_predicted_values,  
                                          xgb_reversed_predicted_values, 
                                          svm_difference,
                                          xgb_difference,
                                          svm_difference_percentage, 
                                          xgb_difference_percentage]).transpose(), 
             columns = ['date', 
                        'y', 
                        'svm_y_hat', 
                        "xgb_y_hat", 
                        'svm_error', 
                        "xgb_error", 
                        'svm_error %', 
                        'xgb_error %'])

prediction_table

